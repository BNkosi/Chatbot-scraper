How to Develop a Self-Driving Car in Under a Week
15 Sep 2019
Jason Webster

Self-driving cars are a major topic of interest in automobile research, because they’re safer and more fuel-efficient. As a machine-learning hobbyist intrigued by self-driving cars, I’ve always wanted to build one myself in a simulated environment. By using the power and accessibility of deep-learning, I achieved this in under a week. In this article, I’ll demonstrate the value of deep-learning by explaining how I did it and how others can reproduce this too.


My goal
Growing-up, I used to love driving-games. Getting home from school and racing against my brother in Gran Turismo, or chasing after cars in Need for Speed, used to be the order of the day. But I had always wondered how the game’s AI acted the way it did, how it produced human-like opponents. Now that I’m older, I know that the AI in those games would have used path following algorithms and state control to simulate human-like behaviour.
Although it’s a great solution in a simulated world, it rapidly falls apart in the real world where there are no states, no predetermined paths, and no room for error. We have to act on what we see… I was intrigued, and gave myself this task: build a self-driving car in a game environment, where the only information it has access to is what it can see.

My goal

The constraints
Due to what this task required me to do, and the limited resources I had at the time, I had to set some reasonable constraints. These included:

Time: I mostly considered myself a machine-learning hobbyist, and not a professional, and at the time I was also busy with my Masters. Thus, I had to put a limit on the time I spent on this project. I chose two weeks, but ended-up only needing one.
Budget: I only had a 2GB graphics card at my disposable. As I knew I would be using deep learning for this problem, my GPU memory was a relevant concern as deep learning typically requires a large amount of expensive, heavy-duty memory.
Performance: Given my time constraints, I knew I wouldn’t be able to make a groundbreaking algorithm. As such, I limited my performance goal to: if I could build a model that could drive reasonably well with little-to-no human input, it would be a success.


The constraints
Time: I mostly considered myself a machine-learning hobbyist, and not a professional, and at the time I was also busy with my Masters. Thus, I had to put a limit on the time I spent on this project. I chose two weeks, but ended-up only needing one.
Budget: I only had a 2GB graphics card at my disposable. As I knew I would be using deep learning for this problem, my GPU memory was a relevant concern as deep learning typically requires a large amount of expensive, heavy-duty memory.
Performance: Given my time constraints, I knew I wouldn’t be able to make a groundbreaking algorithm. As such, I limited my performance goal to: if I could build a model that could drive reasonably well with little-to-no human input, it would be a success.

Figuring out how to go about it
I found a few useful YouTube videos on the topic from Siraj Raval and SethBling, as well as a very informative article by sentdex. Having looked at these, I had a better idea of what I needed to:

Choose a model small enough to be able to fit on my 2GB GPU with a game running in the background, but also accurate enough to be able to make reasonable predictions.
Choose a game  to act as the simulated environment.
Record myself playing a game, monitoring my keystrokes as I do so in order to set up a supervised learning problem.
Use this data to train my model, so that it could make predictions.
Use these predictions to generate keystrokes in the game, so that the model could control the car.

With those steps laid-out, I could buckle-up and get going.

Figuring out how to go about it
Choose a model small enough to be able to fit on my 2GB GPU with a game running in the background, but also accurate enough to be able to make reasonable predictions.
Choose a game  to act as the simulated environment.
Record myself playing a game, monitoring my keystrokes as I do so in order to set up a supervised learning problem.
Use this data to train my model, so that it could make predictions.
Use these predictions to generate keystrokes in the game, so that the model could control the car.

Choose a game  to act as the simulated environment.
Record myself playing a game, monitoring my keystrokes as I do so in order to set up a supervised learning problem.
Use this data to train my model, so that it could make predictions.
Use these predictions to generate keystrokes in the game, so that the model could control the car.

Record myself playing a game, monitoring my keystrokes as I do so in order to set up a supervised learning problem.
Use this data to train my model, so that it could make predictions.
Use these predictions to generate keystrokes in the game, so that the model could control the car.

Use this data to train my model, so that it could make predictions.
Use these predictions to generate keystrokes in the game, so that the model could control the car.

Use these predictions to generate keystrokes in the game, so that the model could control the car.

Step 1: Choosing a model

Our problem is essentially an image recognition problem, that is: given the current visual information from our game, which direction should we go in? From my experience, I knew that a convolutional neural network was likely the best approach for this case, as they form the backbone of state of the art image recognition models. Given my restraints, I knew I needed a model that was small and easy to compute. I also wanted to make a prediction based off of only the single frame displayed on the screen, as using more than one frame would start taxing my GPU memory budget.

Previous models that have worked extremely well in image recognition tasks include VGG16, Inception, and ResNet50. Given that these models were built to classify millions of images into 1000 categories, they tend to be very large - anywhere between 20 to 150 million parameters. These models were too big and couldn’t make the cut.

Instead, I decided to build a custom neural net based off the VGG16 architecture, which makes use of a number of blocks (a group of multiple layers) with max-pooling and dropout layers between consecutive blocks. Since I wasn’t doing large-scale image recognition, I could adapt the architecture and significantly drop the number of parameters used in-model without significant loss of accuracy.

The architecture I settled on building was a sequential model, with each layer connected to the previous layer as follows:
A convolutional layer with a kernel size of 3x3, a depth of 32 channels, and a stride of two pixels, activated by a ReLU function.Latest Posts
15 Sep 2019
How to Develop a Self-Driving Car in Under a Week.
Jason Webster

15 Sep 2019
4 Tips For Communicating Technical Ideas to a Non-tech Audience
Jason Webster

15 Sep 2019
How Playing Games Inspires My Software Development.
Jacob Clarkson
Lauch your career today 
and start doing Amazing Things